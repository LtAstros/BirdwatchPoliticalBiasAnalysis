{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/costinsmilovici/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/costinsmilovici/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/costinsmilovici/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/costinsmilovici/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from requests_oauthlib import OAuth1Session\n",
    "import json\n",
    "import constants\n",
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import bigrams\n",
    "\n",
    "# import stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains the API key information that will be needed for querying the Twitter API\n",
    "# The sample size for the number of tweets we will use\n",
    "API_KEY_SEC = constants.API_KEY_SEC\n",
    "API_KEY = constants.API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "- https://ucsd.libguides.com/congress_twitter\n",
    "- Twitter API\n",
    "    - User lookup endpoint\n",
    "    - Timelines endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "House = pd.read_csv(\"./Data/HouseTwitter.csv\")\n",
    "Senate = pd.read_csv(\"./Data/SenateTwitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams, Alma</td>\n",
       "      <td>https://twitter.com/RepAdams</td>\n",
       "      <td>NC</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aderholt, Robert</td>\n",
       "      <td>https://twitter.com/Robert_Aderholt</td>\n",
       "      <td>AL</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aguilar, Pete</td>\n",
       "      <td>https://twitter.com/RepPeteAguilar</td>\n",
       "      <td>CA</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allen, Rick</td>\n",
       "      <td>https://twitter.com/RepRickAllen</td>\n",
       "      <td>GA</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allred, Colin</td>\n",
       "      <td>https://twitter.com/RepColinAllred</td>\n",
       "      <td>TX</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                  Link State Party\n",
       "0       Adams, Alma         https://twitter.com/RepAdams    NC     D\n",
       "1  Aderholt, Robert  https://twitter.com/Robert_Aderholt    AL     R\n",
       "2     Aguilar, Pete   https://twitter.com/RepPeteAguilar    CA     D\n",
       "3       Allen, Rick     https://twitter.com/RepRickAllen    GA     R\n",
       "4     Allred, Colin   https://twitter.com/RepColinAllred    TX     D"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Politicians = House.append(Senate).reset_index(drop=True)\n",
    "Politicians.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Politicians[\"Usernames\"] = Politicians[\"Link\"].str.replace(\"https://twitter.com/\",\"\",regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Politicians = Politicians.dropna(subset=[\"Usernames\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Politicians = Politicians[Politicians[\"Party\"] != \"I\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = Politicians[\"Usernames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_arr = []\n",
    "for i in range((len(usernames) // 100)+1):\n",
    "    l = i*100\n",
    "    r = min(len(usernames),(i+1)*100)\n",
    "    search_arr += [\",\".join(usernames[l:r].str.strip())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is Twitter's authentication code for python so it can largely be ignored\n",
    "\n",
    "**Source: https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/main/Tweet-Lookup/get_tweets_with_user_context.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got OAuth token: iizCcAAAAAABcJlTAAABgjxIvBs\n",
      "Please go here and authorize: https://api.twitter.com/oauth/authorize?oauth_token=iizCcAAAAAABcJlTAAABgjxIvBs\n",
      "Paste the PIN here: 9739639\n"
     ]
    }
   ],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "consumer_key = API_KEY\n",
    "consumer_secret = API_KEY_SEC\n",
    "\n",
    "request_token_url = \"https://api.twitter.com/oauth/request_token\"\n",
    "oauth = OAuth1Session(consumer_key, client_secret=consumer_secret)\n",
    "\n",
    "try:\n",
    "    fetch_response = oauth.fetch_request_token(request_token_url)\n",
    "except ValueError:\n",
    "    print(\n",
    "        \"There may have been an issue with the consumer_key or consumer_secret you entered.\"\n",
    "    )\n",
    "\n",
    "resource_owner_key = fetch_response.get(\"oauth_token\")\n",
    "resource_owner_secret = fetch_response.get(\"oauth_token_secret\")\n",
    "print(\"Got OAuth token: %s\" % resource_owner_key)\n",
    "\n",
    "# Get authorization\n",
    "base_authorization_url = \"https://api.twitter.com/oauth/authorize\"\n",
    "authorization_url = oauth.authorization_url(base_authorization_url)\n",
    "print(\"Please go here and authorize: %s\" % authorization_url)\n",
    "verifier = input(\"Paste the PIN here: \")\n",
    "\n",
    "# Get the access token\n",
    "access_token_url = \"https://api.twitter.com/oauth/access_token\"\n",
    "oauth = OAuth1Session(\n",
    "    consumer_key,\n",
    "    client_secret=consumer_secret,\n",
    "    resource_owner_key=resource_owner_key,\n",
    "    resource_owner_secret=resource_owner_secret,\n",
    "    verifier=verifier,\n",
    ")\n",
    "oauth_tokens = oauth.fetch_access_token(access_token_url)\n",
    "\n",
    "\n",
    "access_token = oauth_tokens[\"oauth_token\"]\n",
    "access_token_secret = oauth_tokens[\"oauth_token_secret\"]\n",
    "\n",
    "# Make the request\n",
    "oauth = OAuth1Session(\n",
    "    consumer_key,\n",
    "    client_secret=consumer_secret,\n",
    "    resource_owner_key=access_token,\n",
    "    resource_owner_secret=access_token_secret,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "API_UIDs = []\n",
    "\n",
    "for users in search_arr:\n",
    "    params = {\"usernames\": users, \"user.fields\": \"username,id\"}\n",
    "    response = oauth.get(\n",
    "        \"https://api.twitter.com/2/users/by\", params=params\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    json_response = response.json()\n",
    "    dataframed_response = pd.DataFrame(json_response[\"data\"])[[\"id\",\"username\"]]\n",
    "    API_UIDs += [dataframed_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_df = pd.concat(API_UIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Politicians = Politicians.merge(uid_df,left_on=\"Usernames\",right_on=\"username\").drop(columns=\"username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>State</th>\n",
       "      <th>Party</th>\n",
       "      <th>Usernames</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams, Alma</td>\n",
       "      <td>https://twitter.com/RepAdams</td>\n",
       "      <td>NC</td>\n",
       "      <td>D</td>\n",
       "      <td>RepAdams</td>\n",
       "      <td>2916086925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aderholt, Robert</td>\n",
       "      <td>https://twitter.com/Robert_Aderholt</td>\n",
       "      <td>AL</td>\n",
       "      <td>R</td>\n",
       "      <td>Robert_Aderholt</td>\n",
       "      <td>76452765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aguilar, Pete</td>\n",
       "      <td>https://twitter.com/RepPeteAguilar</td>\n",
       "      <td>CA</td>\n",
       "      <td>D</td>\n",
       "      <td>RepPeteAguilar</td>\n",
       "      <td>3018670151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allen, Rick</td>\n",
       "      <td>https://twitter.com/RepRickAllen</td>\n",
       "      <td>GA</td>\n",
       "      <td>R</td>\n",
       "      <td>RepRickAllen</td>\n",
       "      <td>2964287128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allred, Colin</td>\n",
       "      <td>https://twitter.com/RepColinAllred</td>\n",
       "      <td>TX</td>\n",
       "      <td>D</td>\n",
       "      <td>RepColinAllred</td>\n",
       "      <td>1078355119920562176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Warren, Elizabeth</td>\n",
       "      <td>https://twitter.com/SenWarren</td>\n",
       "      <td>MA</td>\n",
       "      <td>D</td>\n",
       "      <td>SenWarren</td>\n",
       "      <td>970207298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Whitehouse, Sheldon</td>\n",
       "      <td>https://twitter.com/SenWhitehouse</td>\n",
       "      <td>RI</td>\n",
       "      <td>D</td>\n",
       "      <td>SenWhitehouse</td>\n",
       "      <td>242555999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Wicker, Roger F.</td>\n",
       "      <td>https://twitter.com/SenatorWicker</td>\n",
       "      <td>MS</td>\n",
       "      <td>R</td>\n",
       "      <td>SenatorWicker</td>\n",
       "      <td>264219447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Wyden, Ron</td>\n",
       "      <td>https://twitter.com/RonWyden</td>\n",
       "      <td>OR</td>\n",
       "      <td>D</td>\n",
       "      <td>RonWyden</td>\n",
       "      <td>250188760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Young, Todd</td>\n",
       "      <td>https://twitter.com/SenToddYoung</td>\n",
       "      <td>IN</td>\n",
       "      <td>R</td>\n",
       "      <td>SenToddYoung</td>\n",
       "      <td>234128524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                                  Link State Party  \\\n",
       "0            Adams, Alma         https://twitter.com/RepAdams    NC     D   \n",
       "1       Aderholt, Robert  https://twitter.com/Robert_Aderholt    AL     R   \n",
       "2          Aguilar, Pete   https://twitter.com/RepPeteAguilar    CA     D   \n",
       "3            Allen, Rick     https://twitter.com/RepRickAllen    GA     R   \n",
       "4          Allred, Colin   https://twitter.com/RepColinAllred    TX     D   \n",
       "..                   ...                                  ...   ...   ...   \n",
       "521    Warren, Elizabeth        https://twitter.com/SenWarren    MA     D   \n",
       "522  Whitehouse, Sheldon    https://twitter.com/SenWhitehouse    RI     D   \n",
       "523     Wicker, Roger F.    https://twitter.com/SenatorWicker    MS     R   \n",
       "524           Wyden, Ron         https://twitter.com/RonWyden    OR     D   \n",
       "525          Young, Todd     https://twitter.com/SenToddYoung    IN     R   \n",
       "\n",
       "           Usernames                   id  \n",
       "0           RepAdams           2916086925  \n",
       "1    Robert_Aderholt             76452765  \n",
       "2     RepPeteAguilar           3018670151  \n",
       "3       RepRickAllen           2964287128  \n",
       "4     RepColinAllred  1078355119920562176  \n",
       "..               ...                  ...  \n",
       "521        SenWarren            970207298  \n",
       "522    SenWhitehouse            242555999  \n",
       "523    SenatorWicker            264219447  \n",
       "524         RonWyden            250188760  \n",
       "525     SenToddYoung            234128524  \n",
       "\n",
       "[526 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_tweets = []\n",
    "for user_id in Politicians[\"id\"]:\n",
    "    params = {\"tweet.fields\": \"author_id,text\", \"max_results\": 100}\n",
    "    response = oauth.get(\n",
    "        f\"https://api.twitter.com/2/users/{user_id}/tweets\", params=params\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    json_response = response.json()\n",
    "    if json_response.get(\"data\",False):\n",
    "        dataframed_response = pd.DataFrame(json_response[\"data\"])\n",
    "        API_tweets += [dataframed_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_tweets = pd.concat(API_tweets).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "poli_tweets = poli_tweets.drop_duplicates(subset=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poli_tweets = poli_tweets[[\"author_id\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = Politicians[[\"id\",\"Party\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_tweets = poli_tweets.merge(right,left_on=\"author_id\",right_on=\"id\").drop(columns=[\"id\",\"author_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_tweets.to_csv(\"./Data/ClassifierData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_tweets = pd.read_csv(\"./Data/ClassifierData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_tweets[\"text\"] = (\n",
    "    party_tweets[\"text\"]\n",
    "        .str.replace(\"^RT @.*:\",\"\",regex=True)\n",
    "        .str.replace(\" https://t.*$\",\"\",regex=True)\n",
    "        .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(tweet_tokens, stop_words = stop_words):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(raw_str):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = remove_noise(tokenizer.tokenize(raw_str))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = party_tweets[\"text\"]\n",
    "y = party_tweets[\"Party\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.806):\n",
      "{'tfidf__max_df': 0.6, 'tfidf__min_df': 1}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', tfidf), ('svc', SVC(kernel='linear'))])\n",
    "param_grid = {\n",
    "    \"tfidf__min_df\": np.round(np.linspace(1,20,4)).astype(int),\n",
    "    \"tfidf__max_df\": np.linspace(.6,1,3),\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=2, cv=2)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.6, sublinear_tf=True,\n",
       "                                 tokenizer=<function tokenize at 0x7fddc4c94280>)),\n",
       "                ('svc', SVC(kernel='linear'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf = True,max_df=0.6,min_df=1,tokenizer=tokenize)\n",
    "pipe = Pipeline([('tfidf', tfidf), ('svc', SVC(kernel='linear'))])\n",
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Models/fitted_svm.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe, './Models/fitted_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = joblib.load('./Models/fitted_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdwatch_tweets = pd.read_csv(\"./Data/birdwatch_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdwatch_tweets[\"predicted_label\"] = my_model.predict(birdwatch_tweets[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    0.541872\n",
       "D    0.458128\n",
       "Name: predicted_label, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birdwatch_tweets[\"predicted_label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdwatch_tweets.to_csv(\"./Data/birdwatch_tweets_with_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
